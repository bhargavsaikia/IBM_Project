{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n",
      "total chars: 57\n",
      "nb sequences: 200285\n",
      "Vectorization...\n",
      "Build model...\n",
      "Epoch 1/60\n",
      "200285/200285 [==============================] - 103s 512us/step - loss: 1.9721\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" every\n",
      "sense--may perhaps one day be the\"\n",
      " every\n",
      "sense--may perhaps one day be the such a life in the morality and the servers and in the stright in the sees the servers of the servering of the strenged and and in the may be stright of the server the serves to be precent and and in the sense of the precess of the anter and a the servers of the servers of the sees to be precent the see in the server and in the servers and sense the self is a precised and in the precent and in th\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" every\n",
      "sense--may perhaps one day be the\"\n",
      " every\n",
      "sense--may perhaps one day be the \"greass an adresting soul for the sight in the seevered to the servers morality a pleasurally of so experientical one prepogated and the charned is a prition of the destrition and recired and his recoption as and in the streverated but is the churing and in the spiriting are which all must in the preason and a\n",
      "condicts in the about and the bention can benefous of his believe a christed to be perc\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" every\n",
      "sense--may perhaps one day be the\"\n",
      " every\n",
      "sense--may perhaps one day be their\n",
      "bungred and michom: recised, bad and so the more, learng; what\n",
      "\"why indomsing sode say a philosoitalisal to reaked, and\n",
      "a\n",
      "lower--is more this beood? but himself in so moyt with shaye a prefief eres a pover him imfere that scientibuled with such pay to aether men in whe ineperstance, and conception--orgee,\n",
      "the grack. craretions of strates and to daves in the acist, founding, greth\" uskly, is sob\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" every\n",
      "sense--may perhaps one day be the\"\n",
      " every\n",
      "sense--may perhaps one day be them inteets aboun re\n",
      "pretineds sbuti)es, ow un tho\n",
      "pon again as\n",
      "ed, posspina uonteriting. yreates , impory\n",
      "inwercain, (orst in gratire lambtrience that ye philoso-follve-stride mayuffere\n",
      "us aswait\n",
      "penhanding hat\n",
      "baff--much\n",
      "sol. be scoople. hum by the prece, ave ay bull\n",
      "an last--in reue).\n",
      "\n",
      "found, by \"hi fomm the ramiing thought. \n",
      "one imerature\"a\"vad, grate.  opbsenowrnating the i wis ope conttrepd or\n",
      "Epoch 2/60\n",
      "200285/200285 [==============================] - 99s 493us/step - loss: 1.6203\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"only the significance of an encouragemen\"\n",
      "only the significance of an encouragement, and be the properation of the sense and in the developed to the the suppose to the sense of the power of the propeing and inviduality of the wastes to the most man in the sense of the supposition of the sense of the contemples to the man in the devidual contempt of the truth the more supposition of the sense of the personality to the the among the power of the can be a self-contempt of the mora\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"only the significance of an encouragemen\"\n",
      "only the significance of an encouragements of the self--even to the whatever of men the truth in the to the does to a fact the doown of the\n",
      "reality of the be in such his is a goodd and whather marely to the whole as it is a one knowledge to interpons of seven and indeed and all a sen to to life. it is its contradicise as the great, when the greater and oftered previlution of man are in the good god the \"good\" and even with the and all t\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"only the significance of an encouragemen\"\n",
      "only the significance of an encouragement questens manser ma unglebous good.\n",
      "in be kelt to enge, of there as have a chulf is to have gorritific in this civelaliwem,\n",
      "for the purtocian, which\n",
      "stall-might power and othetherstund aw he\n",
      "curtie. the grate-a general\n",
      "englise, with it all usvess and,\n",
      "\"to his begratime of\n",
      "the isselfiwhcit\n",
      "nowaultigg; and howef which was\n",
      "me know some and ficw, in the world the man would deeld for the\n",
      "other, to the\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"only the significance of an encouragemen\"\n",
      "only the significance of an encouragementl reat6:\n",
      "which has time is one cittud that matrive consani1utat as i yath his rands its fcalation fosm awagener, for which i contestoind vanouss just, jeked and powerful phyile\n",
      "mades hisllys.--his whkever. de authore alds fouthe, be\n",
      "horul fach\n",
      "of a\n",
      "sevenases confent.\n",
      "there\n",
      "do!bition, and westen\n",
      "rid atmod, hat, hame for the ambleds mucitation for say.\n",
      "perhaps is hhwards in extent, takes of the moa\n",
      "Epoch 3/60\n",
      "192000/200285 [===========================>..] - ETA: 5s - loss: 1.5312"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "path = get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=60,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
